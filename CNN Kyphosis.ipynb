{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\WINSOME\\\\kyphosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kyphosis</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number</th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kyphosis  Age  Number  Start\n",
       "0   absent   71       3      5\n",
       "1   absent  158       3     14\n",
       "2  present  128       4      5\n",
       "3   absent    2       5      1\n",
       "4   absent    1       4     15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Kyphosis', 'Age', 'Number', 'Start'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Age', 'Number', 'Start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =data ['Kyphosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y= le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (from scikit-learn->sklearn) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\winsome\\appdata\\local\\conda\\conda\\envs\\tf\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4,input_dim = 3,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense( 3, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer ='adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 9.1163 - accuracy: 0.1875\n",
      "Epoch 2/150\n",
      "64/64 [==============================] - 0s 423us/step - loss: 7.3537 - accuracy: 0.1875\n",
      "Epoch 3/150\n",
      "64/64 [==============================] - 0s 317us/step - loss: 5.6386 - accuracy: 0.1875\n",
      "Epoch 4/150\n",
      "64/64 [==============================] - 0s 467us/step - loss: 3.9614 - accuracy: 0.1875\n",
      "Epoch 5/150\n",
      "64/64 [==============================] - 0s 412us/step - loss: 2.9172 - accuracy: 0.1875\n",
      "Epoch 6/150\n",
      "64/64 [==============================] - 0s 271us/step - loss: 2.2536 - accuracy: 0.1875\n",
      "Epoch 7/150\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.7204 - accuracy: 0.1875\n",
      "Epoch 8/150\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.3345 - accuracy: 0.2031\n",
      "Epoch 9/150\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.1204 - accuracy: 0.5312\n",
      "Epoch 10/150\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.0211 - accuracy: 0.5625\n",
      "Epoch 11/150\n",
      "64/64 [==============================] - 0s 330us/step - loss: 0.9701 - accuracy: 0.5938\n",
      "Epoch 12/150\n",
      "64/64 [==============================] - 0s 475us/step - loss: 0.9496 - accuracy: 0.5938\n",
      "Epoch 13/150\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.70 - 0s 307us/step - loss: 0.9277 - accuracy: 0.5938\n",
      "Epoch 14/150\n",
      "64/64 [==============================] - 0s 369us/step - loss: 0.9111 - accuracy: 0.6094\n",
      "Epoch 15/150\n",
      "64/64 [==============================] - 0s 599us/step - loss: 0.8942 - accuracy: 0.6094\n",
      "Epoch 16/150\n",
      "64/64 [==============================] - 0s 435us/step - loss: 0.8759 - accuracy: 0.6094\n",
      "Epoch 17/150\n",
      "64/64 [==============================] - 0s 278us/step - loss: 0.8590 - accuracy: 0.6094\n",
      "Epoch 18/150\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.8447 - accuracy: 0.6094\n",
      "Epoch 19/150\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.8271 - accuracy: 0.6250\n",
      "Epoch 20/150\n",
      "64/64 [==============================] - 0s 458us/step - loss: 0.8127 - accuracy: 0.6406\n",
      "Epoch 21/150\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.7949 - accuracy: 0.6406\n",
      "Epoch 22/150\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.7805 - accuracy: 0.6562\n",
      "Epoch 23/150\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.7683 - accuracy: 0.6562\n",
      "Epoch 24/150\n",
      "64/64 [==============================] - 0s 377us/step - loss: 0.7539 - accuracy: 0.6719\n",
      "Epoch 25/150\n",
      "64/64 [==============================] - 0s 273us/step - loss: 0.7404 - accuracy: 0.6719\n",
      "Epoch 26/150\n",
      "64/64 [==============================] - 0s 342us/step - loss: 0.7313 - accuracy: 0.6875\n",
      "Epoch 27/150\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9013 - accuracy: 0.60 - 0s 281us/step - loss: 0.7192 - accuracy: 0.6875\n",
      "Epoch 28/150\n",
      "64/64 [==============================] - 0s 473us/step - loss: 0.7085 - accuracy: 0.6875\n",
      "Epoch 29/150\n",
      "64/64 [==============================] - 0s 291us/step - loss: 0.6992 - accuracy: 0.6875\n",
      "Epoch 30/150\n",
      "64/64 [==============================] - 0s 350us/step - loss: 0.6907 - accuracy: 0.6719\n",
      "Epoch 31/150\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.6813 - accuracy: 0.6719\n",
      "Epoch 32/150\n",
      "64/64 [==============================] - 0s 277us/step - loss: 0.6749 - accuracy: 0.6719\n",
      "Epoch 33/150\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.6650 - accuracy: 0.6719\n",
      "Epoch 34/150\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.6597 - accuracy: 0.6719\n",
      "Epoch 35/150\n",
      "64/64 [==============================] - 0s 247us/step - loss: 0.6492 - accuracy: 0.6719\n",
      "Epoch 36/150\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.6427 - accuracy: 0.6719\n",
      "Epoch 37/150\n",
      "64/64 [==============================] - 0s 259us/step - loss: 0.6357 - accuracy: 0.6719\n",
      "Epoch 38/150\n",
      "64/64 [==============================] - 0s 273us/step - loss: 0.6299 - accuracy: 0.6875\n",
      "Epoch 39/150\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.6218 - accuracy: 0.6875\n",
      "Epoch 40/150\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.6192 - accuracy: 0.6875\n",
      "Epoch 41/150\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.6124 - accuracy: 0.6875\n",
      "Epoch 42/150\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.6050 - accuracy: 0.6875\n",
      "Epoch 43/150\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.6015 - accuracy: 0.6875\n",
      "Epoch 44/150\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.5972 - accuracy: 0.6875\n",
      "Epoch 45/150\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.5929 - accuracy: 0.6875\n",
      "Epoch 46/150\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.5908 - accuracy: 0.6875\n",
      "Epoch 47/150\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.5864 - accuracy: 0.6875\n",
      "Epoch 48/150\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.5820 - accuracy: 0.7031\n",
      "Epoch 49/150\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.5774 - accuracy: 0.7031\n",
      "Epoch 50/150\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.5737 - accuracy: 0.7031\n",
      "Epoch 51/150\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.5701 - accuracy: 0.7188\n",
      "Epoch 52/150\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.5668 - accuracy: 0.7188\n",
      "Epoch 53/150\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.5634 - accuracy: 0.7188\n",
      "Epoch 54/150\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.5623 - accuracy: 0.7188\n",
      "Epoch 55/150\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.5619 - accuracy: 0.7188\n",
      "Epoch 56/150\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.5580 - accuracy: 0.7344\n",
      "Epoch 57/150\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.5541 - accuracy: 0.7500\n",
      "Epoch 58/150\n",
      "64/64 [==============================] - 0s 235us/step - loss: 0.5513 - accuracy: 0.7500\n",
      "Epoch 59/150\n",
      "64/64 [==============================] - 0s 253us/step - loss: 0.5490 - accuracy: 0.7500\n",
      "Epoch 60/150\n",
      "64/64 [==============================] - 0s 361us/step - loss: 0.5480 - accuracy: 0.7500\n",
      "Epoch 61/150\n",
      "64/64 [==============================] - 0s 226us/step - loss: 0.5468 - accuracy: 0.7656\n",
      "Epoch 62/150\n",
      "64/64 [==============================] - 0s 284us/step - loss: 0.5452 - accuracy: 0.7656\n",
      "Epoch 63/150\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.5433 - accuracy: 0.7656\n",
      "Epoch 64/150\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.5416 - accuracy: 0.7656\n",
      "Epoch 65/150\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.5405 - accuracy: 0.7656\n",
      "Epoch 66/150\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.5406 - accuracy: 0.7656\n",
      "Epoch 67/150\n",
      "64/64 [==============================] - 0s 220us/step - loss: 0.5384 - accuracy: 0.7656\n",
      "Epoch 68/150\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.5378 - accuracy: 0.7812\n",
      "Epoch 69/150\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7767 - accuracy: 0.60 - 0s 239us/step - loss: 0.5370 - accuracy: 0.7812\n",
      "Epoch 70/150\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.5364 - accuracy: 0.7812\n",
      "Epoch 71/150\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.5384 - accuracy: 0.7812\n",
      "Epoch 72/150\n",
      "64/64 [==============================] - 0s 222us/step - loss: 0.5356 - accuracy: 0.7969\n",
      "Epoch 73/150\n",
      "64/64 [==============================] - 0s 316us/step - loss: 0.5348 - accuracy: 0.7969\n",
      "Epoch 74/150\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.5334 - accuracy: 0.7969\n",
      "Epoch 75/150\n",
      "64/64 [==============================] - 0s 290us/step - loss: 0.5340 - accuracy: 0.7969\n",
      "Epoch 76/150\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.5339 - accuracy: 0.7969\n",
      "Epoch 77/150\n",
      "64/64 [==============================] - 0s 255us/step - loss: 0.5339 - accuracy: 0.7969\n",
      "Epoch 78/150\n",
      "64/64 [==============================] - 0s 255us/step - loss: 0.5384 - accuracy: 0.7969\n",
      "Epoch 79/150\n",
      "64/64 [==============================] - 0s 222us/step - loss: 0.5348 - accuracy: 0.7969\n",
      "Epoch 80/150\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.5325 - accuracy: 0.7969\n",
      "Epoch 81/150\n",
      "64/64 [==============================] - 0s 333us/step - loss: 0.5357 - accuracy: 0.7969\n",
      "Epoch 82/150\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.5315 - accuracy: 0.8125\n",
      "Epoch 83/150\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.5315 - accuracy: 0.8125\n",
      "Epoch 84/150\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.5314 - accuracy: 0.8125\n",
      "Epoch 85/150\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.5315 - accuracy: 0.8125\n",
      "Epoch 86/150\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.5308 - accuracy: 0.8125\n",
      "Epoch 87/150\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.5274 - accuracy: 0.8125\n",
      "Epoch 88/150\n",
      "64/64 [==============================] - 0s 590us/step - loss: 0.5296 - accuracy: 0.8125\n",
      "Epoch 89/150\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.5306 - accuracy: 0.8125\n",
      "Epoch 90/150\n",
      "64/64 [==============================] - 0s 317us/step - loss: 0.5308 - accuracy: 0.8125\n",
      "Epoch 91/150\n",
      "64/64 [==============================] - 0s 395us/step - loss: 0.5297 - accuracy: 0.8125\n",
      "Epoch 92/150\n",
      "64/64 [==============================] - 0s 316us/step - loss: 0.5279 - accuracy: 0.8125\n",
      "Epoch 93/150\n",
      "64/64 [==============================] - 0s 320us/step - loss: 0.5278 - accuracy: 0.8125\n",
      "Epoch 94/150\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.5289 - accuracy: 0.8125\n",
      "Epoch 95/150\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.5295 - accuracy: 0.8125\n",
      "Epoch 96/150\n",
      "64/64 [==============================] - 0s 277us/step - loss: 0.5280 - accuracy: 0.8125\n",
      "Epoch 97/150\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.5283 - accuracy: 0.8125\n",
      "Epoch 98/150\n",
      "64/64 [==============================] - 0s 311us/step - loss: 0.5275 - accuracy: 0.8125\n",
      "Epoch 99/150\n",
      "64/64 [==============================] - 0s 228us/step - loss: 0.5265 - accuracy: 0.8125\n",
      "Epoch 100/150\n",
      "64/64 [==============================] - 0s 315us/step - loss: 0.5266 - accuracy: 0.8125\n",
      "Epoch 101/150\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.5268 - accuracy: 0.8125\n",
      "Epoch 102/150\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.5289 - accuracy: 0.8125\n",
      "Epoch 103/150\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.5261 - accuracy: 0.8125\n",
      "Epoch 104/150\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.5266 - accuracy: 0.8125\n",
      "Epoch 105/150\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.5263 - accuracy: 0.8125\n",
      "Epoch 106/150\n",
      "64/64 [==============================] - 0s 271us/step - loss: 0.5255 - accuracy: 0.8125\n",
      "Epoch 107/150\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.5251 - accuracy: 0.8125\n",
      "Epoch 108/150\n",
      "64/64 [==============================] - 0s 326us/step - loss: 0.5255 - accuracy: 0.8125\n",
      "Epoch 109/150\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.5252 - accuracy: 0.8125\n",
      "Epoch 110/150\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.5249 - accuracy: 0.8125\n",
      "Epoch 111/150\n",
      "64/64 [==============================] - 0s 334us/step - loss: 0.5250 - accuracy: 0.8125\n",
      "Epoch 112/150\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.5246 - accuracy: 0.8125\n",
      "Epoch 113/150\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.80 - 0s 266us/step - loss: 0.5249 - accuracy: 0.8125\n",
      "Epoch 114/150\n",
      "64/64 [==============================] - 0s 342us/step - loss: 0.5279 - accuracy: 0.8125\n",
      "Epoch 115/150\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.5249 - accuracy: 0.8125\n",
      "Epoch 116/150\n",
      "64/64 [==============================] - 0s 241us/step - loss: 0.5245 - accuracy: 0.8125\n",
      "Epoch 117/150\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.5267 - accuracy: 0.8125\n",
      "Epoch 118/150\n",
      "64/64 [==============================] - 0s 260us/step - loss: 0.5250 - accuracy: 0.8125\n",
      "Epoch 119/150\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.5238 - accuracy: 0.8125\n",
      "Epoch 120/150\n",
      "64/64 [==============================] - 0s 279us/step - loss: 0.5236 - accuracy: 0.8125\n",
      "Epoch 121/150\n",
      "64/64 [==============================] - 0s 260us/step - loss: 0.5234 - accuracy: 0.8125\n",
      "Epoch 122/150\n",
      "64/64 [==============================] - 0s 324us/step - loss: 0.5243 - accuracy: 0.8125\n",
      "Epoch 123/150\n",
      "64/64 [==============================] - 0s 237us/step - loss: 0.5236 - accuracy: 0.8125\n",
      "Epoch 124/150\n",
      "64/64 [==============================] - 0s 284us/step - loss: 0.5240 - accuracy: 0.8125\n",
      "Epoch 125/150\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.5240 - accuracy: 0.8125\n",
      "Epoch 126/150\n",
      "64/64 [==============================] - 0s 319us/step - loss: 0.5240 - accuracy: 0.8125\n",
      "Epoch 127/150\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.5298 - accuracy: 0.8125\n",
      "Epoch 128/150\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.5223 - accuracy: 0.8125\n",
      "Epoch 129/150\n",
      "64/64 [==============================] - 0s 345us/step - loss: 0.5235 - accuracy: 0.8125\n",
      "Epoch 130/150\n",
      "64/64 [==============================] - 0s 280us/step - loss: 0.5230 - accuracy: 0.8125\n",
      "Epoch 131/150\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.5232 - accuracy: 0.8125\n",
      "Epoch 132/150\n",
      "64/64 [==============================] - 0s 338us/step - loss: 0.5220 - accuracy: 0.8125\n",
      "Epoch 133/150\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.5214 - accuracy: 0.8125\n",
      "Epoch 134/150\n",
      "64/64 [==============================] - 0s 286us/step - loss: 0.5215 - accuracy: 0.8125\n",
      "Epoch 135/150\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.5225 - accuracy: 0.8125\n",
      "Epoch 136/150\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.5218 - accuracy: 0.8125\n",
      "Epoch 137/150\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.5208 - accuracy: 0.8125\n",
      "Epoch 138/150\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5744 - accuracy: 0.70 - 0s 249us/step - loss: 0.5229 - accuracy: 0.8125\n",
      "Epoch 139/150\n",
      "64/64 [==============================] - 0s 289us/step - loss: 0.5230 - accuracy: 0.8125\n",
      "Epoch 140/150\n",
      "64/64 [==============================] - 0s 274us/step - loss: 0.5193 - accuracy: 0.8125\n",
      "Epoch 141/150\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.5207 - accuracy: 0.8125\n",
      "Epoch 142/150\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.5208 - accuracy: 0.8125\n",
      "Epoch 143/150\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.5221 - accuracy: 0.8125\n",
      "Epoch 144/150\n",
      "64/64 [==============================] - 0s 325us/step - loss: 0.5189 - accuracy: 0.8125\n",
      "Epoch 145/150\n",
      "64/64 [==============================] - 0s 242us/step - loss: 0.5221 - accuracy: 0.8125\n",
      "Epoch 146/150\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.5208 - accuracy: 0.8125\n",
      "Epoch 147/150\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.5267 - accuracy: 0.8125\n",
      "Epoch 148/150\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.5191 - accuracy: 0.8125\n",
      "Epoch 149/150\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.5190 - accuracy: 0.8125\n",
      "Epoch 150/150\n",
      "64/64 [==============================] - 0s 315us/step - loss: 0.5208 - accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d9051e9508>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs =150, batch_size =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "17/17 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 70.58823704719543\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy : {accuracy*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', n_jobs=1, solver='liblinear')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=logmodel.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.88      0.60      0.60        17\n",
      "weighted avg       0.82      0.76      0.70        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
